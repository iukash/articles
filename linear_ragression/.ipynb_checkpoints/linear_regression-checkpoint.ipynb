{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6919378",
   "metadata": {},
   "source": [
    "## Линейная регрессия. Разбор математики и реализации на python.\n",
    "Тема  линейной регресии рассмотрена множество раз в различных источниках, но,  как говорится, \"нет такой избитой темы, которую нельзя ударить еще раз\". В данной статье рассмотрим указанную тему, используя как  математические выкладки, так и код python, пытаясь соблюсти баланс на  грани простоты и должном уровне для понимания математических основ.\n",
    "\n",
    "Линейная регрессия представляется из себя регриссионную модель  зависимости одной (объясняемой, зависимой) переменной от другой или  нескольких других переменных (фактров, регрессоров, независимых  переменных) с линейной функцией зависимости. Рассмотрим модель линейной  регрессии, при которой зависимая переменная зависит лишь от одного  фактора, тогда функция, описывающуя зависимость y от x будет иметь следующий вид: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cfa7cf",
   "metadata": {},
   "source": [
    "$$f(x)=w_0+w_1*x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59376148",
   "metadata": {},
   "source": [
    "и задача сводится к нахождению весовых коэффициентов $w_0$ и $w_1$, таких что такая прямая максимально \"хорошо\" будет описывать исходные данные. Для этого зададим функцию ошибки, минимизация которой обеспечит подбор весов $w_0$ и $w_1$, используя метод наименьших квадратов:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515429de",
   "metadata": {},
   "source": [
    "$$MSE=\\sum_{i=0}^{n}(y_i - f(x_i))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9158ed46",
   "metadata": {},
   "source": [
    "или подставив уравнение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e422a",
   "metadata": {},
   "source": [
    "$$MSE=\\sum_{i=0}^{n}(y_i - w_0 - w_1*x_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169c172",
   "metadata": {},
   "source": [
    "Минимизируем функцию ошибки $MSE$ аналитическим способом, для этого найдем частные производные по $w_0$ и $w_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af857b15",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial MSE(w_0, w_1)}{\\partial w_0} = -2*\\sum_{i=0}^{n}(y_i - w_0 -w_1*x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b10ce6",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial MSE(w_0, w_1)}{\\partial w_1} = -2*\\sum_{i=0}^{n}(y_i - w_0 -w_1*x_i)*x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d8d3ce",
   "metadata": {},
   "source": [
    "И приравняв их к нулю получим систему уравнений, решение которой обеспечит минимизацию функции потерь MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d434b0a",
   "metadata": {},
   "source": [
    "$$\\cases{0={-2*\\sum_{i=0}^{n}(y_i - w_0 -w_1*x_i)}\\\\0 = -2*\\sum_{i=0}^{n}((y_i - w_0 -w_1*x_i)*x_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa895fa2",
   "metadata": {},
   "source": [
    "Раскроем сумму"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c3738",
   "metadata": {},
   "source": [
    "$$\\cases{0={- w_0*n + \\sum_{i=0}^{n}(y_i  -w_1*x_i)}\\\\0 = -2*\\sum_{i=0}^{n}(y_i*x_i) - w_0*\\sum_{i=0}^{n}x_i -w_1*\\sum_{i=0}^{n}x_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d53290",
   "metadata": {},
   "source": [
    "Выразим $w_0$ из первого уравнения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152bd21e",
   "metadata": {},
   "source": [
    "$$w_0=\\frac{\\sum_{i=0}^{n}(y_i)}{n} - w_1*\\frac{\\sum_{i=0}^{n}(x_i)}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648bf839",
   "metadata": {},
   "source": [
    "Подставив во второе уравнение решим относительно $w_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c6c83f",
   "metadata": {},
   "source": [
    "$$0 = \\sum_{i=0}^{n}(y_i*x_i) - (\\frac{\\sum_{i=0}^{n}y_i}{n} - w_1 \\frac{\\sum_{i=0}^{n}x_i}{n})*\\sum_{i=0}^{n}x_i^2 - w_1*\\sum_{i=0}^{n}x_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bce403f",
   "metadata": {},
   "source": [
    "$$0 = \\sum_{i=0}^{n}(y_i*x_i) - \\frac{\\sum_{i=0}^{n}y_i\\sum_{i=0}^{n}x_i}{n} + w_1 \\frac{\\sum_{i=0}^{n}x_i\\sum_{i=0}^{n}x_i}{n} - w_1*\\sum_{i=0}^{n}x_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de126dcf",
   "metadata": {},
   "source": [
    "И выразив $w_1$ последнего уравнения получим"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77294d4",
   "metadata": {},
   "source": [
    "$$w_1 = \\frac{\\frac{\\sum_{i=0}^{n}(x_i*\\sum_{i=0}^{n}(y_i))}{n}-\\sum_{i=0}^{n}(y_i*x_i)}\n",
    "{\\frac{\\sum_{i=0}^{n}(x_i*\\sum_{i=0}^{n}(x_i))}{n}-\\sum_{i=0}^{n}(x_i^2)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75c5d5",
   "metadata": {},
   "source": [
    "Задача решена, однако представленный способ слабо распространим на большое количество фичей, уже при появлении второго признака вывод становится достаточно громоздким, не говоря уже о большем количестве признаков.\n",
    "\n",
    "Справиться с этой задачей нам поможет матричный способ представления функции потерь и ее минимизация путем дифференцирования и нахождения экстремума в матричном виде.\n",
    "\n",
    "Предположим, что дана следующая таблица с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a0169",
   "metadata": {},
   "source": [
    "|f1 |f2 |f3 | y |\n",
    "|---|---|---|---|\n",
    "|x11|x12|x13|y1 |\n",
    "|...|...|...|...|\n",
    "|x1n|x2n|x3n|yn |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41815172",
   "metadata": {},
   "source": [
    "Для вычисления интерсепта (коэффициента $w_0$) необходимо к таблице добавить столбец слева с фактором f0 все значения которого равны 0. И тогда столбцы f0-f3 (по количеству столбцов не ограничены, можно считать $fn$) можно выделить в матрицу X, целевую переменную в матрицу-столбец $y$, а искомые коэффициенты можно представить в виде вектора $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd1b56",
   "metadata": {},
   "source": [
    "$$ \\left [\\begin {array} {cccc}\n",
    "X_1&Y_1^2\\\\\n",
    "X_2 & Y_2^2\\\\\n",
    "\\ldots \\\\\n",
    "X_n&Y_n^2\n",
    "\\end{array} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b7fb3",
   "metadata": {},
   "source": [
    "$$X = \\left [\\begin{array}{cccc}x_{01}&x_{11}&x_{12}&x_{13}\\\\\n",
    "...&...&...&...\\\\\n",
    "x_{0n}&x_{1n}&x_{1n}&x_{1n} \\end{array}\\right] \n",
    "y = \\left [\\begin{array}{cccc} \n",
    "y_0 \\\\ y_1 \\\\ y_2 \\\\ y_3 \\end{array}\\right]\n",
    "w = \\left [\\begin{array}{cccc} \n",
    "w_0 & w_1 & w_2 & w_3 \\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388c9d3",
   "metadata": {},
   "source": [
    "Тогда функцию потерь $MSE=\\sum_{i=0}^{n}(y_i-f(x_i))^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1096fd00",
   "metadata": {},
   "source": [
    "можно представить в следующем виде"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23256a",
   "metadata": {},
   "source": [
    "$$ MSE=(y-X*w)^T(y-X*w)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9c8a7",
   "metadata": {},
   "source": [
    "Представим в виде скалярного произведения < > и вычислим производную используя дифференциал"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4564c",
   "metadata": {},
   "source": [
    "$$ \\partial(<(y-X*w),(y-X*w)>)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca8b64",
   "metadata": {},
   "source": [
    "используя правило "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0696ffb2",
   "metadata": {},
   "source": [
    "$$ \\partial(<x,x>) = <2x,\\partial x>$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2790ccd",
   "metadata": {},
   "source": [
    "приведем формулу к следующему виду"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2304a62e",
   "metadata": {},
   "source": [
    "$$(<2*(y-X*w),\\partial (y-X*w)>)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de0bd2c",
   "metadata": {},
   "source": [
    "Поскольку дифференциал разницы равен разнице дифференциалов, дифференциал константы ($y$) равен нулю и константу (в данном случае матрицу $X$) можно вынести за знак дифференциала, получим"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ed6da",
   "metadata": {},
   "source": [
    "$$(<2*(y-X*w), X*\\partial w>)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff12f71",
   "metadata": {},
   "source": [
    "Используя свойство скалярного произведения перенесем матрицу $X$ справа налево незабыв транспонировать ее"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d41af",
   "metadata": {},
   "source": [
    "$$(<2*X^T*(y-X*w), \\partial w>)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508984a8",
   "metadata": {},
   "source": [
    "Собственно, то что слева и есть дифференциал, найдем экстремум приравняв его к нулю и решив по параметрам $w$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6204521",
   "metadata": {},
   "source": [
    "$$2*X^T*(X*w-y)=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa3add",
   "metadata": {},
   "source": [
    "раскроем скобки и перенесем значения без w вправо"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34bbdc9",
   "metadata": {},
   "source": [
    "$$X^T*X*w = X^T*y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128a4f7",
   "metadata": {},
   "source": [
    "Домножим слева обе стороны равенства на обратную матрицу произведения транспонированной матрицы $X$ на $X$ для выражения вектора w, тогда получим"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8bbb85",
   "metadata": {},
   "source": [
    "$$w = (X^T*X)^{-1}*X^T*y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede84e2",
   "metadata": {},
   "source": [
    "Аналитическое решение получено, переходим к реализации на python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594a52d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты полученные расчетным путем [0.05994939 0.42839296 0.09249473 0.46642055]\n",
      "Коэффициенты полученные с использованием библиотеки sklearn [0.05994939 0.42839296 0.09249473 0.46642055]\n"
     ]
    }
   ],
   "source": [
    "#импорт необходимых библиотек\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#зададим начальные условия\n",
    "f0 = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "f1 = np.array([1.1, 2.1, 3.1, 4.4, 5.2, 6.4, 7.1, 8.2, 9.4, 10.5])\n",
    "f2 = np.array([1.4, 2.3, 3.4, 4.1, 5.5, 6.2, 7.3, 8.4, 9.2, 10.1])\n",
    "f3 = np.array([1.2, 2.2, 3.4, 4.2, 5.3, 6.2, 7.3, 8.4, 9.2, 10.3])\n",
    "y = np.array([[1.2], [2.2], [3.3], [4.3], [5.2], [6.3], [7.2], [8.3], [9.3], [10.2]])\n",
    "w = np.array([np.nan, np.nan, np.nan, np.nan])\n",
    "X = np.array([f0, f1, f2, f3]).T\n",
    "\n",
    "#рассчитаем коэффициенты используя выведенную формулу\n",
    "coef_matrix = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)\n",
    "print(f'Коэффициенты полученные расчетным путем {coef_matrix.T[0]}')\n",
    "\n",
    "#проверим расчет используя библиотеку sklearn\n",
    "model = LinearRegression().fit(X, y)\n",
    "coef_sklearn = model.coef_.T\n",
    "coef_sklearn[0] = model.intercept_\n",
    "print(f'Коэффициенты полученные с использованием библиотеки sklearn {coef_sklearn.T[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7384b6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
